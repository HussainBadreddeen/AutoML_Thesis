{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN28ksHw7VCN6NhWRV1N540",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HussainBadreddeen/AutoML_Thesis/blob/main/H2o_thesis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "voRCIQMwON5f",
        "outputId": "2005ba66-779b-4412-a55a-7c8dc91c7738"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# df_normalized_reviews.to_csv(\"/content/drive/My Drive/processed_data.csv\", index=False, encoding=\"utf-8-sig\") #fixed it utf-8 doesnt wokr although it did before\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "#load it back\n",
        "df_normalized_reviews2 = pd.read_csv(\"/content/drive/My Drive/processed_data.csv\") #the nan row comes back somehow\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(df_normalized_reviews2[df_normalized_reviews2.isna().any(axis=1)])\n",
        "empty_or_nan_values = df_normalized_reviews2[df_normalized_reviews2.isna().any(axis=1)]\n",
        "empty_or_nan_values\n",
        "\n",
        "df_normalized_reviews2 = df_normalized_reviews2[df_normalized_reviews2['stemmed_text'].notna()]  # remove rows where stemmed_text is NaN\n",
        "print(df_normalized_reviews2[df_normalized_reviews2.isna().any(axis=1)])\n",
        "empty_or_nan_values = df_normalized_reviews2[df_normalized_reviews2.isna().any(axis=1)]\n",
        "empty_or_nan_values\n",
        "#i saved the dataset again after here and now it doesnt need removing this line again so no need to run this cell anymore"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "K-aFPVimOXEk",
        "outputId": "1dc49358-4d64-4fbd-95b1-f347e8935e56"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty DataFrame\n",
            "Columns: [rating, review, normalized_review, tokens, filtered_tokens, stemmed_text]\n",
            "Index: []\n",
            "Empty DataFrame\n",
            "Columns: [rating, review, normalized_review, tokens, filtered_tokens, stemmed_text]\n",
            "Index: []\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [rating, review, normalized_review, tokens, filtered_tokens, stemmed_text]\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b3186761-cb2d-4c3a-9dd2-aa7cb8bec2de\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rating</th>\n",
              "      <th>review</th>\n",
              "      <th>normalized_review</th>\n",
              "      <th>tokens</th>\n",
              "      <th>filtered_tokens</th>\n",
              "      <th>stemmed_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b3186761-cb2d-4c3a-9dd2-aa7cb8bec2de')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b3186761-cb2d-4c3a-9dd2-aa7cb8bec2de button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b3186761-cb2d-4c3a-9dd2-aa7cb8bec2de');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_2a305ec0-45ce-4160-ad00-2de51b3db40d\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('empty_or_nan_values')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_2a305ec0-45ce-4160-ad00-2de51b3db40d button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('empty_or_nan_values');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "empty_or_nan_values",
              "repr_error": "Out of range float values are not JSON compliant: nan"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer # this is good: https://www.youtube.com/watch?v=rcovF6S1oFI\n",
        "tfidf_vectorizer = TfidfVectorizer(\n",
        "     # max_features=10000,      # Limit to 10k features # update i will use just min and max and wont test chunking on all 71k unique words/features\n",
        "    min_df=5,                # Remove rare words (appearing in less than 5 documents/rows)\n",
        "    max_df=0.8,              # Remove overly common words (appearing in more than 80% of documents)\n",
        "    dtype=np.float32          # Use float32 to save memory\n",
        ")\n",
        "\n",
        "\n",
        "# Fit and transform the stemmed text vocab\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(df_normalized_reviews2[\"stemmed_text\"])\n",
        "\n",
        "# Print the shape of the matrix\n",
        "print(\"Shape of the TF-IDF matrix:\", tfidf_matrix.shape)\n",
        "#converting the sparse matrix to dense in case i need to use the dense matrix\n",
        "# X_dense = tfidf_matrix.astype(np.float32).toarray()\n",
        "\n",
        "# np.save('C:/Users/hussa/OneDrive/Desktop/thesis_code/tfidf_dense.npy', X_dense)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ka4bRtawO2cz",
        "outputId": "b8e71c4f-d867-4aa8-b96d-2514ec233dbc"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of the TF-IDF matrix: (102961, 9819)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#update using 71k words seems unprofessional might overfit and introduce noise and computation problems as im having them already.\n",
        "\n",
        "#will probably use min_df and max_df to limit words more and try dense matrix again on drive first then maybe local but will always opt for drive till exhaustion"
      ],
      "metadata": {
        "id": "gtCvb1V-fw5O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#loading dense matrix and ratings from drive"
      ],
      "metadata": {
        "id": "jYv04wXUZMA0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Load pre-saved files #the labels are already mapped and the dense matrix is already ready and is 3.7gb (9.8k words converted using float32 isntead of 64) insteado of 55gb with all words\n",
        "# X = np.load('C:/Users/hussa/OneDrive/Desktop/thesis_code/tfidf_dense.npy', mmap_mode='r')  # efficient read\n",
        "# y = np.load('C:/Users/hussa/OneDrive/Desktop/thesis_code/labels_binary.npy')\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "X = np.load('/content/drive/My Drive/tfidf_dense.npy', mmap_mode='r')  # efficient read for dense matrix but i wont use it cause ram never handles it so i use the sparse matrix\n",
        "y = np.load('/content/drive/My Drive/labels_binary.npy')\n"
      ],
      "metadata": {
        "id": "R6e8EMrGZLLL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f02545f-d4f8-4c40-8084-9b2383c36d01"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# H2o attempt in running with dense matrix and mapped ratings"
      ],
      "metadata": {
        "id": "J-gyA3G_ZsKt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install h2o"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mzQoVcQ8gkp3",
        "outputId": "7113df17-0aea-4efc-a4fe-929105d224cd"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: h2o in /usr/local/lib/python3.11/dist-packages (3.46.0.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from h2o) (2.32.3)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (from h2o) (0.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->h2o) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->h2o) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->h2o) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->h2o) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import h2o\n",
        "from h2o.automl import H2OAutoML\n",
        "from h2o.estimators import H2OXGBoostEstimator\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "h2o.init()\n",
        "\n",
        "# Convert to H2OFrame\n",
        "X_h2o = h2o.H2OFrame(tfidf_matrix)\n",
        "y_h2o = h2o.H2OFrame(y.reshape(-1, 1), column_names=['rating']).asfactor()\n",
        "# Combine features (X) and target (y) into a single H2OFrame\n",
        "df_h2o = X_h2o.cbind(y_h2o)\n",
        "# Specify the target column and features\n",
        "target_column = 'rating'\n",
        "feature_columns = df_h2o.columns\n",
        "feature_columns.remove(target_column)\n",
        "\n",
        "train, test = df_h2o.split_frame(ratios=[.8], seed=1)#seed =1 to ensure that the random operations (like the train-test split or cross-validation splits) produce the same results each time the code is run so we can reproduce same results\n",
        "\n",
        "\n",
        "#if i dont specify include algo =\"algo_name\"\n",
        "#h20 then tries these:\n",
        "# GLM\tLinear models (good for interpretability)\n",
        "# GBM\tH2O's own gradient boosting implementation\n",
        "# XGBoost\tHighly efficient tree-based model (enabled if system supports it — Colab does)\n",
        "# DRF\tDistributed Random Forest\n",
        "# DeepLearning\tSimple fully connected feed-forward neural net\n",
        "# StackedEnsemble\tCombines the best-performing models\n",
        "# XRT\tVariation of Random Forest with extra randomness (might not always show up depending on settings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "NRvcKOkt_gBJ",
        "outputId": "a56cba61-51f3-4315-f647-9822367d5637"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking whether there is an H2O instance running at http://localhost:54321. connected.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "--------------------------  -----------------------------------------------------------------------------------------\n",
              "H2O_cluster_uptime:         14 mins 48 secs\n",
              "H2O_cluster_timezone:       Etc/UTC\n",
              "H2O_data_parsing_timezone:  UTC\n",
              "H2O_cluster_version:        3.46.0.7\n",
              "H2O_cluster_version_age:    21 days, 21 hours and 48 minutes\n",
              "H2O_cluster_name:           H2O_from_python_unknownUser_a7c96j\n",
              "H2O_cluster_total_nodes:    1\n",
              "H2O_cluster_free_memory:    3.027 Gb\n",
              "H2O_cluster_total_cores:    2\n",
              "H2O_cluster_allowed_cores:  2\n",
              "H2O_cluster_status:         locked, healthy\n",
              "H2O_connection_url:         http://localhost:54321\n",
              "H2O_connection_proxy:       {\"http\": null, \"https\": null, \"colab_language_server\": \"/usr/colab/bin/language_service\"}\n",
              "H2O_internal_security:      False\n",
              "Python_version:             3.11.12 final\n",
              "--------------------------  -----------------------------------------------------------------------------------------"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "\n",
              "#h2o-table-2.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-2 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-2 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-2 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-2 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-2 .h2o-table th,\n",
              "#h2o-table-2 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-2 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-2\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption></caption>\n",
              "    <thead></thead>\n",
              "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
              "<td>14 mins 48 secs</td></tr>\n",
              "<tr><td>H2O_cluster_timezone:</td>\n",
              "<td>Etc/UTC</td></tr>\n",
              "<tr><td>H2O_data_parsing_timezone:</td>\n",
              "<td>UTC</td></tr>\n",
              "<tr><td>H2O_cluster_version:</td>\n",
              "<td>3.46.0.7</td></tr>\n",
              "<tr><td>H2O_cluster_version_age:</td>\n",
              "<td>21 days, 21 hours and 48 minutes</td></tr>\n",
              "<tr><td>H2O_cluster_name:</td>\n",
              "<td>H2O_from_python_unknownUser_a7c96j</td></tr>\n",
              "<tr><td>H2O_cluster_total_nodes:</td>\n",
              "<td>1</td></tr>\n",
              "<tr><td>H2O_cluster_free_memory:</td>\n",
              "<td>3.027 Gb</td></tr>\n",
              "<tr><td>H2O_cluster_total_cores:</td>\n",
              "<td>2</td></tr>\n",
              "<tr><td>H2O_cluster_allowed_cores:</td>\n",
              "<td>2</td></tr>\n",
              "<tr><td>H2O_cluster_status:</td>\n",
              "<td>locked, healthy</td></tr>\n",
              "<tr><td>H2O_connection_url:</td>\n",
              "<td>http://localhost:54321</td></tr>\n",
              "<tr><td>H2O_connection_proxy:</td>\n",
              "<td>{\"http\": null, \"https\": null, \"colab_language_server\": \"/usr/colab/bin/language_service\"}</td></tr>\n",
              "<tr><td>H2O_internal_security:</td>\n",
              "<td>False</td></tr>\n",
              "<tr><td>Python_version:</td>\n",
              "<td>3.11.12 final</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
            "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "aml = H2OAutoML(max_models=10, seed=1, nfolds=5, max_runtime_secs=10800)\n",
        "aml.train(x=feature_columns, y=target_column, training_frame=train)\n",
        "# [evaluate + print leaderboard + save model...]\n",
        "# View the leaderboard (top-performing models)\n",
        "lb = aml.leaderboard\n",
        "print(lb)\n",
        "\n",
        "# Predict on the test set\n",
        "preds = aml.predict(test)\n",
        "\n",
        "# Evaluate the predictions\n",
        "print(\"\\nSample Predictions:\\n\", preds.head())\n",
        "\n",
        "# Get list of models from leaderboard\n",
        "model_ids = list(aml.leaderboard['model_id'].as_data_frame().values.flatten())\n",
        "\n",
        "# Inspect top model (best one)\n",
        "top_model = h2o.get_model(model_ids[0])\n",
        "print(f\"\\nBest model ID: {model_ids[0]}\")\n",
        "print(\"Algorithm used:\", top_model.algo)\n",
        "\n",
        "# Summary\n",
        "try:\n",
        "    print(\"\\nModel Summary:\")\n",
        "    print(top_model.summary())\n",
        "except:\n",
        "    print(\"No summary available for this model.\")\n",
        "\n",
        "# Hyperparameters\n",
        "print(\"\\nHyperparameters:\")\n",
        "print(top_model.params)\n",
        "\n",
        "# Variable importance (if supported)\n",
        "try:\n",
        "    print(\"\\nVariable Importance:\")\n",
        "    print(top_model.varimp(use_pandas=True))\n",
        "except:\n",
        "    print(\"Variable importance not available for this model.\")\n",
        "\n",
        "# Evaluate on test set\n",
        "perf = top_model.model_performance(test_data=test)\n",
        "print(\"\\nModel Performance on Test Set:\")\n",
        "print(perf)\n",
        "print(\"\\nConfusion Matrix:\\n\", perf.confusion_matrix())\n",
        "print(\"\\nAUC:\", perf.auc())\n",
        "\n",
        "model_path = h2o.save_model(model=top_model, path=\"/content/drive/My Drive/h2o_model\", force=True)\n",
        "print(\"Model saved to:\", model_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hjsP3O7kBuk-",
        "outputId": "b55cb0c6-24b7-4038-da97-3965c1af7717"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AutoML progress: |███████████████████████████████████████████████████████████████| (done) 100%\n",
            "model_id                                 auc    logloss     aucpr    mean_per_class_error      rmse        mse\n",
            "XGBoost_1_AutoML_1_20250418_135015  0.97507    0.196236  0.970262               0.0744532  0.237984  0.0566365\n",
            "GLM_1_AutoML_1_20250418_135015      0.959024   0.257488  0.950583               0.0972575  0.272323  0.0741599\n",
            "[2 rows x 7 columns]\n",
            "\n",
            "xgboost prediction progress: |███████████████████████████████████████████████████| (done) 100%\n",
            "\n",
            "Sample Predictions:\n",
            "   predict           p0        p1\n",
            "        1  0.00121421   0.998786\n",
            "        1  0.000745356  0.999255\n",
            "        1  0.000979662  0.99902\n",
            "        1  0.00142336   0.998577\n",
            "        1  0.0021807    0.997819\n",
            "        1  0.0200986    0.979901\n",
            "        1  0.414866     0.585134\n",
            "        1  0.00707048   0.99293\n",
            "        1  0.00744319   0.992557\n",
            "        1  0.202766     0.797234\n",
            "[10 rows x 3 columns]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/h2o/frame.py:1983: H2ODependencyWarning: Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install polars and pyarrow and use it as pandas_df = h2o_df.as_data_frame(use_multi_thread=True)\n",
            "\n",
            "  warnings.warn(\"Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best model ID: XGBoost_1_AutoML_1_20250418_135015\n",
            "Algorithm used: xgboost\n",
            "\n",
            "Model Summary:\n",
            "Model Summary: \n",
            "    number_of_trees\n",
            "--  -----------------\n",
            "    81\n",
            "\n",
            "Hyperparameters:\n",
            "{'model_id': {'default': None, 'actual': {'__meta': {'schema_version': 3, 'schema_name': 'ModelKeyV3', 'schema_type': 'Key<Model>'}, 'name': 'XGBoost_1_AutoML_1_20250418_135015', 'type': 'Key<Model>', 'URL': '/3/Models/XGBoost_1_AutoML_1_20250418_135015'}, 'input': None}, 'training_frame': {'default': None, 'actual': {'__meta': {'schema_version': 3, 'schema_name': 'FrameKeyV3', 'schema_type': 'Key<Frame>'}, 'name': 'AutoML_1_20250418_135015_training_py_6_sid_926e', 'type': 'Key<Frame>', 'URL': '/3/Frames/AutoML_1_20250418_135015_training_py_6_sid_926e'}, 'input': {'__meta': {'schema_version': 3, 'schema_name': 'FrameKeyV3', 'schema_type': 'Key<Frame>'}, 'name': 'AutoML_1_20250418_135015_training_py_6_sid_926e', 'type': 'Key<Frame>', 'URL': '/3/Frames/AutoML_1_20250418_135015_training_py_6_sid_926e'}}, 'validation_frame': {'default': None, 'actual': None, 'input': None}, 'nfolds': {'default': 0, 'actual': 5, 'input': 5}, 'keep_cross_validation_models': {'default': True, 'actual': False, 'input': False}, 'keep_cross_validation_predictions': {'default': False, 'actual': True, 'input': True}, 'keep_cross_validation_fold_assignment': {'default': False, 'actual': False, 'input': False}, 'score_each_iteration': {'default': False, 'actual': False, 'input': False}, 'fold_assignment': {'default': 'AUTO', 'actual': 'Modulo', 'input': 'Modulo'}, 'fold_column': {'default': None, 'actual': None, 'input': None}, 'response_column': {'default': None, 'actual': {'__meta': {'schema_version': 3, 'schema_name': 'ColSpecifierV3', 'schema_type': 'VecSpecifier'}, 'column_name': 'rating', 'is_member_of_frames': None}, 'input': {'__meta': {'schema_version': 3, 'schema_name': 'ColSpecifierV3', 'schema_type': 'VecSpecifier'}, 'column_name': 'rating', 'is_member_of_frames': None}}, 'ignored_columns': {'default': None, 'actual': [], 'input': []}, 'ignore_const_cols': {'default': True, 'actual': True, 'input': True}, 'offset_column': {'default': None, 'actual': None, 'input': None}, 'weights_column': {'default': None, 'actual': None, 'input': None}, 'stopping_rounds': {'default': 0, 'actual': 0, 'input': 3}, 'stopping_metric': {'default': 'AUTO', 'actual': 'logloss', 'input': 'logloss'}, 'stopping_tolerance': {'default': 0.001, 'actual': 0.003485166892911656, 'input': 0.003485166892911656}, 'max_runtime_secs': {'default': 0.0, 'actual': 0.0, 'input': 0.0}, 'seed': {'default': -1, 'actual': 1, 'input': 1}, 'distribution': {'default': 'AUTO', 'actual': 'bernoulli', 'input': 'bernoulli'}, 'tweedie_power': {'default': 1.5, 'actual': 1.5, 'input': 1.5}, 'categorical_encoding': {'default': 'AUTO', 'actual': 'OneHotInternal', 'input': 'AUTO'}, 'quiet_mode': {'default': True, 'actual': True, 'input': True}, 'checkpoint': {'default': None, 'actual': None, 'input': None}, 'export_checkpoints_dir': {'default': None, 'actual': None, 'input': None}, 'custom_metric_func': {'default': None, 'actual': None, 'input': None}, 'ntrees': {'default': 50, 'actual': 81, 'input': 10000}, 'max_depth': {'default': 6, 'actual': 15, 'input': 15}, 'min_rows': {'default': 1.0, 'actual': 10.0, 'input': 10.0}, 'min_child_weight': {'default': 1.0, 'actual': 10.0, 'input': 1.0}, 'learn_rate': {'default': 0.3, 'actual': 0.3, 'input': 0.3}, 'eta': {'default': 0.3, 'actual': 0.3, 'input': 0.3}, 'sample_rate': {'default': 1.0, 'actual': 0.6, 'input': 0.6}, 'subsample': {'default': 1.0, 'actual': 0.6, 'input': 1.0}, 'col_sample_rate': {'default': 1.0, 'actual': 0.8, 'input': 0.8}, 'colsample_bylevel': {'default': 1.0, 'actual': 0.8, 'input': 1.0}, 'col_sample_rate_per_tree': {'default': 1.0, 'actual': 0.8, 'input': 0.8}, 'colsample_bytree': {'default': 1.0, 'actual': 0.8, 'input': 1.0}, 'colsample_bynode': {'default': 1.0, 'actual': 1.0, 'input': 1.0}, 'max_abs_leafnode_pred': {'default': 0.0, 'actual': 0.0, 'input': 0.0}, 'max_delta_step': {'default': 0.0, 'actual': 0.0, 'input': 0.0}, 'monotone_constraints': {'default': None, 'actual': None, 'input': None}, 'interaction_constraints': {'default': None, 'actual': None, 'input': None}, 'score_tree_interval': {'default': 0, 'actual': 5, 'input': 5}, 'min_split_improvement': {'default': 0.0, 'actual': 0.0, 'input': 0.0}, 'gamma': {'default': 0.0, 'actual': 0.0, 'input': 0.0}, 'nthread': {'default': -1, 'actual': -1, 'input': -1}, 'save_matrix_directory': {'default': None, 'actual': None, 'input': None}, 'build_tree_one_node': {'default': False, 'actual': False, 'input': False}, 'parallelize_cross_validation': {'default': True, 'actual': True, 'input': True}, 'calibrate_model': {'default': False, 'actual': False, 'input': False}, 'calibration_frame': {'default': None, 'actual': None, 'input': None}, 'calibration_method': {'default': 'AUTO', 'actual': 'PlattScaling', 'input': 'AUTO'}, 'max_bins': {'default': 256, 'actual': 256, 'input': 256}, 'max_leaves': {'default': 0, 'actual': 0, 'input': 0}, 'sample_type': {'default': 'uniform', 'actual': 'uniform', 'input': 'uniform'}, 'normalize_type': {'default': 'tree', 'actual': 'tree', 'input': 'tree'}, 'rate_drop': {'default': 0.0, 'actual': 0.0, 'input': 0.0}, 'one_drop': {'default': False, 'actual': False, 'input': False}, 'skip_drop': {'default': 0.0, 'actual': 0.0, 'input': 0.0}, 'tree_method': {'default': 'auto', 'actual': 'exact', 'input': 'auto'}, 'grow_policy': {'default': 'depthwise', 'actual': 'depthwise', 'input': 'depthwise'}, 'booster': {'default': 'gbtree', 'actual': 'gbtree', 'input': 'gbtree'}, 'reg_lambda': {'default': 1.0, 'actual': 1.0, 'input': 1.0}, 'reg_alpha': {'default': 0.0, 'actual': 0.0, 'input': 0.0}, 'dmatrix_type': {'default': 'auto', 'actual': 'sparse', 'input': 'auto'}, 'backend': {'default': 'auto', 'actual': 'cpu', 'input': 'auto'}, 'gpu_id': {'default': None, 'actual': None, 'input': None}, 'gainslift_bins': {'default': -1, 'actual': -1, 'input': -1}, 'auc_type': {'default': 'AUTO', 'actual': 'AUTO', 'input': 'AUTO'}, 'scale_pos_weight': {'default': 1.0, 'actual': 1.0, 'input': 1.0}, 'eval_metric': {'default': None, 'actual': None, 'input': None}, 'score_eval_metric_only': {'default': False, 'actual': False, 'input': False}}\n",
            "\n",
            "Variable Importance:\n",
            "    variable  relative_importance  scaled_importance  percentage\n",
            "0      C8493         11081.948242           1.000000    0.097577\n",
            "1      C5335          9319.831055           0.840992    0.082062\n",
            "2      C1058          9082.544922           0.819580    0.079972\n",
            "3      C3373          9079.483398           0.819304    0.079946\n",
            "4      C4132          8993.889648           0.811580    0.079192\n",
            "..       ...                  ...                ...         ...\n",
            "457    C1061             2.676392           0.000242    0.000024\n",
            "458    C8910             2.397608           0.000216    0.000021\n",
            "459    C1551             2.041748           0.000184    0.000018\n",
            "460    C5279             1.209583           0.000109    0.000011\n",
            "461    C2941             0.823120           0.000074    0.000007\n",
            "\n",
            "[462 rows x 4 columns]\n",
            "\n",
            "Model Performance on Test Set:\n",
            "ModelMetricsBinomial: xgboost\n",
            "** Reported on test data. **\n",
            "\n",
            "MSE: 0.056719078913396795\n",
            "RMSE: 0.23815767657876744\n",
            "LogLoss: 0.19688080657509371\n",
            "Mean Per-Class Error: 0.07578477337873468\n",
            "AUC: 0.9747044709329523\n",
            "AUCPR: 0.9700761614898094\n",
            "Gini: 0.9494089418659046\n",
            "\n",
            "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.414814523675225\n",
            "       0     1      Error    Rate\n",
            "-----  ----  -----  -------  ----------------\n",
            "0      9247  1058   0.1027   (1058.0/10305.0)\n",
            "1      505   9822   0.0489   (505.0/10327.0)\n",
            "Total  9752  10880  0.0758   (1563.0/20632.0)\n",
            "\n",
            "Maximum Metrics: Maximum metrics at their respective thresholds\n",
            "metric                       threshold    value     idx\n",
            "---------------------------  -----------  --------  -----\n",
            "max f1                       0.414815     0.926298  230\n",
            "max f2                       0.200072     0.951132  294\n",
            "max f0point5                 0.764752     0.930864  129\n",
            "max accuracy                 0.503885     0.925019  206\n",
            "max precision                0.999548     1         0\n",
            "max recall                   0.000645602  1         398\n",
            "max specificity              0.999548     1         0\n",
            "max absolute_mcc             0.503885     0.850164  206\n",
            "max min_per_class_accuracy   0.551192     0.923598  193\n",
            "max mean_per_class_accuracy  0.503885     0.92501   206\n",
            "max tns                      0.999548     10305     0\n",
            "max fns                      0.999548     10072     0\n",
            "max fps                      0.000305449  10305     399\n",
            "max tps                      0.000645602  10327     398\n",
            "max tnr                      0.999548     1         0\n",
            "max fnr                      0.999548     0.975307  0\n",
            "max fpr                      0.000305449  1         399\n",
            "max tpr                      0.000645602  1         398\n",
            "\n",
            "Gains/Lift Table: Avg response rate: 50.05 %, avg score: 50.24 %\n",
            "group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
            "-------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
            "1        0.010033                    0.999385           1.99787     1.99787            1                0.999622     1                           0.999622            0.0200445       0.0200445                  99.787    99.787             0.0200445\n",
            "2        0.0200174                   0.999091           1.99787     1.99787            1                0.99924      1                           0.999432            0.0199477       0.0399923                  99.787    99.787             0.0399923\n",
            "3        0.0300019                   0.998818           1.97847     1.99141            0.990291         0.998962     0.996769                    0.999275            0.019754        0.0597463                  97.8473   99.1415            0.0595522\n",
            "4        0.0400349                   0.998531           1.98822     1.99061            0.995169         0.998687     0.996368                    0.999128            0.0199477       0.079694                   98.8218   99.0613            0.0794029\n",
            "5        0.0500194                   0.998301           1.99787     1.99206            1                0.998444     0.997093                    0.998991            0.0199477       0.0996417                  99.787    99.2062            0.0993506\n",
            "6        0.100039                    0.993801           1.97464     1.98335            0.988372         0.996483     0.992733                    0.997737            0.0987702       0.198412                   97.4639   98.335             0.196956\n",
            "7        0.15001                     0.987732           1.94749     1.9714             0.974782         0.990878     0.986753                    0.995452            0.0973177       0.29573                    94.7487   97.1404            0.291751\n",
            "8        0.200078                    0.980825           1.92824     1.9606             0.96515          0.984479     0.981347                    0.992706            0.096543        0.392273                   92.8244   96.0603            0.384801\n",
            "9        0.300019                    0.957429           1.93005     1.95042            0.966052         0.970959     0.976252                    0.985462            0.192892        0.585165                   93.0047   95.0424            0.5709\n",
            "10       0.40001                     0.881754           1.85842     1.92742            0.930199         0.927933     0.96474                     0.971081            0.185824        0.770989                   85.8416   92.7425            0.74275\n",
            "11       0.5                         0.549273           1.52431     1.84681            0.762967         0.744818     0.924389                    0.925833            0.152416        0.923405                   52.4308   84.6809            0.847713\n",
            "12       0.59999                     0.132117           0.637226    1.64523            0.318953         0.316597     0.823491                    0.824302            0.0637165       0.987121                   -36.2774  64.5228            0.775088\n",
            "13       0.699981                    0.0248183          0.103622    1.42501            0.0518662        0.0621301    0.713267                    0.715428            0.0103612       0.997482                   -89.6378  42.5014            0.595639\n",
            "14       0.799971                    0.0057453          0.020337    1.24944            0.0101794        0.0127164    0.625386                    0.627594            0.0020335       0.999516                   -97.9663  24.944             0.399516\n",
            "15       0.899961                    0.00137281         0.00387372  1.11105            0.00193892       0.00309561   0.556118                    0.558209            0.000387334     0.999903                   -99.6126  11.1051            0.200097\n",
            "16       1                           2.21471e-05        0.00096796  1                  0.000484496      0.000726554  0.500533                    0.502439            9.68335e-05     1                          -99.9032  0                  0\n",
            "\n",
            "Confusion Matrix:\n",
            " Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.414814523675225\n",
            "       0     1      Error    Rate\n",
            "-----  ----  -----  -------  ----------------\n",
            "0      9247  1058   0.1027   (1058.0/10305.0)\n",
            "1      505   9822   0.0489   (505.0/10327.0)\n",
            "Total  9752  10880  0.0758   (1563.0/20632.0)\n",
            "\n",
            "AUC: 0.9747044709329523\n",
            "Model saved to: /content/drive/My Drive/h2o_model/XGBoost_1_AutoML_1_20250418_135015\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "aml_xgb = H2OAutoML(max_models=10, seed=1, nfolds=5, max_runtime_secs=10800, include_algos=[\"XGBoost\"])\n",
        "aml_xgb.train(x=feature_columns, y=target_column, training_frame=train)\n",
        "# [evaluate + print leaderboard + save model...]\n",
        "# View the leaderboard (top-performing models)\n",
        "lb = aml.leaderboard\n",
        "print(lb)\n",
        "\n",
        "# Predict on the test set\n",
        "preds = aml.predict(test)\n",
        "\n",
        "# Evaluate the predictions\n",
        "print(\"\\nSample Predictions:\\n\", preds.head())\n",
        "\n",
        "# Get list of models from leaderboard\n",
        "model_ids = list(aml.leaderboard['model_id'].as_data_frame().values.flatten())\n",
        "\n",
        "# Inspect top model (best one)\n",
        "top_model = h2o.get_model(model_ids[0])\n",
        "print(f\"\\nBest model ID: {model_ids[0]}\")\n",
        "print(\"Algorithm used:\", top_model.algo)\n",
        "\n",
        "# Summary\n",
        "try:\n",
        "    print(\"\\nModel Summary:\")\n",
        "    print(top_model.summary())\n",
        "except:\n",
        "    print(\"No summary available for this model.\")\n",
        "\n",
        "# Hyperparameters\n",
        "print(\"\\nHyperparameters:\")\n",
        "print(top_model.params)\n",
        "\n",
        "# Variable importance (if supported)\n",
        "try:\n",
        "    print(\"\\nVariable Importance:\")\n",
        "    print(top_model.varimp(use_pandas=True))\n",
        "except:\n",
        "    print(\"Variable importance not available for this model.\")\n",
        "\n",
        "# Evaluate on test set\n",
        "perf = top_model.model_performance(test_data=test)\n",
        "print(\"\\nModel Performance on Test Set:\")\n",
        "print(perf)\n",
        "print(\"\\nConfusion Matrix:\\n\", perf.confusion_matrix())\n",
        "print(\"\\nAUC:\", perf.auc())\n",
        "\n",
        "model_path2 = h2o.save_model(model=top_model, path=\"/content/drive/My Drive/h2o_model_xgboost_only\", force=True)\n",
        "print(\"Model saved to:\", model_path2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbJKEHkkBvGr",
        "outputId": "bfb43460-31ae-4e8d-cdf2-8447d3c33045"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AutoML progress: |███████████████████████████████████████████████████████████████| (done) 100%\n",
            "model_id                                 auc    logloss     aucpr    mean_per_class_error      rmse        mse\n",
            "XGBoost_1_AutoML_1_20250418_135015  0.97507    0.196236  0.970262               0.0744532  0.237984  0.0566365\n",
            "GLM_1_AutoML_1_20250418_135015      0.959024   0.257488  0.950583               0.0972575  0.272323  0.0741599\n",
            "[2 rows x 7 columns]\n",
            "\n",
            "xgboost prediction progress: |███████████████████████████████████████████████████| (done) 100%\n",
            "\n",
            "Sample Predictions:\n",
            "   predict           p0        p1\n",
            "        1  0.00121421   0.998786\n",
            "        1  0.000745356  0.999255\n",
            "        1  0.000979662  0.99902\n",
            "        1  0.00142336   0.998577\n",
            "        1  0.0021807    0.997819\n",
            "        1  0.0200986    0.979901\n",
            "        1  0.414866     0.585134\n",
            "        1  0.00707048   0.99293\n",
            "        1  0.00744319   0.992557\n",
            "        1  0.202766     0.797234\n",
            "[10 rows x 3 columns]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/h2o/frame.py:1983: H2ODependencyWarning: Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install polars and pyarrow and use it as pandas_df = h2o_df.as_data_frame(use_multi_thread=True)\n",
            "\n",
            "  warnings.warn(\"Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best model ID: XGBoost_1_AutoML_1_20250418_135015\n",
            "Algorithm used: xgboost\n",
            "\n",
            "Model Summary:\n",
            "Model Summary: \n",
            "    number_of_trees\n",
            "--  -----------------\n",
            "    81\n",
            "\n",
            "Hyperparameters:\n",
            "{'model_id': {'default': None, 'actual': {'__meta': {'schema_version': 3, 'schema_name': 'ModelKeyV3', 'schema_type': 'Key<Model>'}, 'name': 'XGBoost_1_AutoML_1_20250418_135015', 'type': 'Key<Model>', 'URL': '/3/Models/XGBoost_1_AutoML_1_20250418_135015'}, 'input': None}, 'training_frame': {'default': None, 'actual': {'__meta': {'schema_version': 3, 'schema_name': 'FrameKeyV3', 'schema_type': 'Key<Frame>'}, 'name': 'AutoML_1_20250418_135015_training_py_6_sid_926e', 'type': 'Key<Frame>', 'URL': '/3/Frames/AutoML_1_20250418_135015_training_py_6_sid_926e'}, 'input': {'__meta': {'schema_version': 3, 'schema_name': 'FrameKeyV3', 'schema_type': 'Key<Frame>'}, 'name': 'AutoML_1_20250418_135015_training_py_6_sid_926e', 'type': 'Key<Frame>', 'URL': '/3/Frames/AutoML_1_20250418_135015_training_py_6_sid_926e'}}, 'validation_frame': {'default': None, 'actual': None, 'input': None}, 'nfolds': {'default': 0, 'actual': 5, 'input': 5}, 'keep_cross_validation_models': {'default': True, 'actual': False, 'input': False}, 'keep_cross_validation_predictions': {'default': False, 'actual': True, 'input': True}, 'keep_cross_validation_fold_assignment': {'default': False, 'actual': False, 'input': False}, 'score_each_iteration': {'default': False, 'actual': False, 'input': False}, 'fold_assignment': {'default': 'AUTO', 'actual': 'Modulo', 'input': 'Modulo'}, 'fold_column': {'default': None, 'actual': None, 'input': None}, 'response_column': {'default': None, 'actual': {'__meta': {'schema_version': 3, 'schema_name': 'ColSpecifierV3', 'schema_type': 'VecSpecifier'}, 'column_name': 'rating', 'is_member_of_frames': None}, 'input': {'__meta': {'schema_version': 3, 'schema_name': 'ColSpecifierV3', 'schema_type': 'VecSpecifier'}, 'column_name': 'rating', 'is_member_of_frames': None}}, 'ignored_columns': {'default': None, 'actual': [], 'input': []}, 'ignore_const_cols': {'default': True, 'actual': True, 'input': True}, 'offset_column': {'default': None, 'actual': None, 'input': None}, 'weights_column': {'default': None, 'actual': None, 'input': None}, 'stopping_rounds': {'default': 0, 'actual': 0, 'input': 3}, 'stopping_metric': {'default': 'AUTO', 'actual': 'logloss', 'input': 'logloss'}, 'stopping_tolerance': {'default': 0.001, 'actual': 0.003485166892911656, 'input': 0.003485166892911656}, 'max_runtime_secs': {'default': 0.0, 'actual': 0.0, 'input': 0.0}, 'seed': {'default': -1, 'actual': 1, 'input': 1}, 'distribution': {'default': 'AUTO', 'actual': 'bernoulli', 'input': 'bernoulli'}, 'tweedie_power': {'default': 1.5, 'actual': 1.5, 'input': 1.5}, 'categorical_encoding': {'default': 'AUTO', 'actual': 'OneHotInternal', 'input': 'AUTO'}, 'quiet_mode': {'default': True, 'actual': True, 'input': True}, 'checkpoint': {'default': None, 'actual': None, 'input': None}, 'export_checkpoints_dir': {'default': None, 'actual': None, 'input': None}, 'custom_metric_func': {'default': None, 'actual': None, 'input': None}, 'ntrees': {'default': 50, 'actual': 81, 'input': 10000}, 'max_depth': {'default': 6, 'actual': 15, 'input': 15}, 'min_rows': {'default': 1.0, 'actual': 10.0, 'input': 10.0}, 'min_child_weight': {'default': 1.0, 'actual': 10.0, 'input': 1.0}, 'learn_rate': {'default': 0.3, 'actual': 0.3, 'input': 0.3}, 'eta': {'default': 0.3, 'actual': 0.3, 'input': 0.3}, 'sample_rate': {'default': 1.0, 'actual': 0.6, 'input': 0.6}, 'subsample': {'default': 1.0, 'actual': 0.6, 'input': 1.0}, 'col_sample_rate': {'default': 1.0, 'actual': 0.8, 'input': 0.8}, 'colsample_bylevel': {'default': 1.0, 'actual': 0.8, 'input': 1.0}, 'col_sample_rate_per_tree': {'default': 1.0, 'actual': 0.8, 'input': 0.8}, 'colsample_bytree': {'default': 1.0, 'actual': 0.8, 'input': 1.0}, 'colsample_bynode': {'default': 1.0, 'actual': 1.0, 'input': 1.0}, 'max_abs_leafnode_pred': {'default': 0.0, 'actual': 0.0, 'input': 0.0}, 'max_delta_step': {'default': 0.0, 'actual': 0.0, 'input': 0.0}, 'monotone_constraints': {'default': None, 'actual': None, 'input': None}, 'interaction_constraints': {'default': None, 'actual': None, 'input': None}, 'score_tree_interval': {'default': 0, 'actual': 5, 'input': 5}, 'min_split_improvement': {'default': 0.0, 'actual': 0.0, 'input': 0.0}, 'gamma': {'default': 0.0, 'actual': 0.0, 'input': 0.0}, 'nthread': {'default': -1, 'actual': -1, 'input': -1}, 'save_matrix_directory': {'default': None, 'actual': None, 'input': None}, 'build_tree_one_node': {'default': False, 'actual': False, 'input': False}, 'parallelize_cross_validation': {'default': True, 'actual': True, 'input': True}, 'calibrate_model': {'default': False, 'actual': False, 'input': False}, 'calibration_frame': {'default': None, 'actual': None, 'input': None}, 'calibration_method': {'default': 'AUTO', 'actual': 'PlattScaling', 'input': 'AUTO'}, 'max_bins': {'default': 256, 'actual': 256, 'input': 256}, 'max_leaves': {'default': 0, 'actual': 0, 'input': 0}, 'sample_type': {'default': 'uniform', 'actual': 'uniform', 'input': 'uniform'}, 'normalize_type': {'default': 'tree', 'actual': 'tree', 'input': 'tree'}, 'rate_drop': {'default': 0.0, 'actual': 0.0, 'input': 0.0}, 'one_drop': {'default': False, 'actual': False, 'input': False}, 'skip_drop': {'default': 0.0, 'actual': 0.0, 'input': 0.0}, 'tree_method': {'default': 'auto', 'actual': 'exact', 'input': 'auto'}, 'grow_policy': {'default': 'depthwise', 'actual': 'depthwise', 'input': 'depthwise'}, 'booster': {'default': 'gbtree', 'actual': 'gbtree', 'input': 'gbtree'}, 'reg_lambda': {'default': 1.0, 'actual': 1.0, 'input': 1.0}, 'reg_alpha': {'default': 0.0, 'actual': 0.0, 'input': 0.0}, 'dmatrix_type': {'default': 'auto', 'actual': 'sparse', 'input': 'auto'}, 'backend': {'default': 'auto', 'actual': 'cpu', 'input': 'auto'}, 'gpu_id': {'default': None, 'actual': None, 'input': None}, 'gainslift_bins': {'default': -1, 'actual': -1, 'input': -1}, 'auc_type': {'default': 'AUTO', 'actual': 'AUTO', 'input': 'AUTO'}, 'scale_pos_weight': {'default': 1.0, 'actual': 1.0, 'input': 1.0}, 'eval_metric': {'default': None, 'actual': None, 'input': None}, 'score_eval_metric_only': {'default': False, 'actual': False, 'input': False}}\n",
            "\n",
            "Variable Importance:\n",
            "    variable  relative_importance  scaled_importance  percentage\n",
            "0      C8493         11081.948242           1.000000    0.097577\n",
            "1      C5335          9319.831055           0.840992    0.082062\n",
            "2      C1058          9082.544922           0.819580    0.079972\n",
            "3      C3373          9079.483398           0.819304    0.079946\n",
            "4      C4132          8993.889648           0.811580    0.079192\n",
            "..       ...                  ...                ...         ...\n",
            "457    C1061             2.676392           0.000242    0.000024\n",
            "458    C8910             2.397608           0.000216    0.000021\n",
            "459    C1551             2.041748           0.000184    0.000018\n",
            "460    C5279             1.209583           0.000109    0.000011\n",
            "461    C2941             0.823120           0.000074    0.000007\n",
            "\n",
            "[462 rows x 4 columns]\n",
            "\n",
            "Model Performance on Test Set:\n",
            "ModelMetricsBinomial: xgboost\n",
            "** Reported on test data. **\n",
            "\n",
            "MSE: 0.056719078913396795\n",
            "RMSE: 0.23815767657876744\n",
            "LogLoss: 0.19688080657509371\n",
            "Mean Per-Class Error: 0.07578477337873468\n",
            "AUC: 0.9747044709329523\n",
            "AUCPR: 0.9700761614898094\n",
            "Gini: 0.9494089418659046\n",
            "\n",
            "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.414814523675225\n",
            "       0     1      Error    Rate\n",
            "-----  ----  -----  -------  ----------------\n",
            "0      9247  1058   0.1027   (1058.0/10305.0)\n",
            "1      505   9822   0.0489   (505.0/10327.0)\n",
            "Total  9752  10880  0.0758   (1563.0/20632.0)\n",
            "\n",
            "Maximum Metrics: Maximum metrics at their respective thresholds\n",
            "metric                       threshold    value     idx\n",
            "---------------------------  -----------  --------  -----\n",
            "max f1                       0.414815     0.926298  230\n",
            "max f2                       0.200072     0.951132  294\n",
            "max f0point5                 0.764752     0.930864  129\n",
            "max accuracy                 0.503885     0.925019  206\n",
            "max precision                0.999548     1         0\n",
            "max recall                   0.000645602  1         398\n",
            "max specificity              0.999548     1         0\n",
            "max absolute_mcc             0.503885     0.850164  206\n",
            "max min_per_class_accuracy   0.551192     0.923598  193\n",
            "max mean_per_class_accuracy  0.503885     0.92501   206\n",
            "max tns                      0.999548     10305     0\n",
            "max fns                      0.999548     10072     0\n",
            "max fps                      0.000305449  10305     399\n",
            "max tps                      0.000645602  10327     398\n",
            "max tnr                      0.999548     1         0\n",
            "max fnr                      0.999548     0.975307  0\n",
            "max fpr                      0.000305449  1         399\n",
            "max tpr                      0.000645602  1         398\n",
            "\n",
            "Gains/Lift Table: Avg response rate: 50.05 %, avg score: 50.24 %\n",
            "group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
            "-------  --------------------------  -----------------  ----------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
            "1        0.010033                    0.999385           1.99787     1.99787            1                0.999622     1                           0.999622            0.0200445       0.0200445                  99.787    99.787             0.0200445\n",
            "2        0.0200174                   0.999091           1.99787     1.99787            1                0.99924      1                           0.999432            0.0199477       0.0399923                  99.787    99.787             0.0399923\n",
            "3        0.0300019                   0.998818           1.97847     1.99141            0.990291         0.998962     0.996769                    0.999275            0.019754        0.0597463                  97.8473   99.1415            0.0595522\n",
            "4        0.0400349                   0.998531           1.98822     1.99061            0.995169         0.998687     0.996368                    0.999128            0.0199477       0.079694                   98.8218   99.0613            0.0794029\n",
            "5        0.0500194                   0.998301           1.99787     1.99206            1                0.998444     0.997093                    0.998991            0.0199477       0.0996417                  99.787    99.2062            0.0993506\n",
            "6        0.100039                    0.993801           1.97464     1.98335            0.988372         0.996483     0.992733                    0.997737            0.0987702       0.198412                   97.4639   98.335             0.196956\n",
            "7        0.15001                     0.987732           1.94749     1.9714             0.974782         0.990878     0.986753                    0.995452            0.0973177       0.29573                    94.7487   97.1404            0.291751\n",
            "8        0.200078                    0.980825           1.92824     1.9606             0.96515          0.984479     0.981347                    0.992706            0.096543        0.392273                   92.8244   96.0603            0.384801\n",
            "9        0.300019                    0.957429           1.93005     1.95042            0.966052         0.970959     0.976252                    0.985462            0.192892        0.585165                   93.0047   95.0424            0.5709\n",
            "10       0.40001                     0.881754           1.85842     1.92742            0.930199         0.927933     0.96474                     0.971081            0.185824        0.770989                   85.8416   92.7425            0.74275\n",
            "11       0.5                         0.549273           1.52431     1.84681            0.762967         0.744818     0.924389                    0.925833            0.152416        0.923405                   52.4308   84.6809            0.847713\n",
            "12       0.59999                     0.132117           0.637226    1.64523            0.318953         0.316597     0.823491                    0.824302            0.0637165       0.987121                   -36.2774  64.5228            0.775088\n",
            "13       0.699981                    0.0248183          0.103622    1.42501            0.0518662        0.0621301    0.713267                    0.715428            0.0103612       0.997482                   -89.6378  42.5014            0.595639\n",
            "14       0.799971                    0.0057453          0.020337    1.24944            0.0101794        0.0127164    0.625386                    0.627594            0.0020335       0.999516                   -97.9663  24.944             0.399516\n",
            "15       0.899961                    0.00137281         0.00387372  1.11105            0.00193892       0.00309561   0.556118                    0.558209            0.000387334     0.999903                   -99.6126  11.1051            0.200097\n",
            "16       1                           2.21471e-05        0.00096796  1                  0.000484496      0.000726554  0.500533                    0.502439            9.68335e-05     1                          -99.9032  0                  0\n",
            "\n",
            "Confusion Matrix:\n",
            " Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.414814523675225\n",
            "       0     1      Error    Rate\n",
            "-----  ----  -----  -------  ----------------\n",
            "0      9247  1058   0.1027   (1058.0/10305.0)\n",
            "1      505   9822   0.0489   (505.0/10327.0)\n",
            "Total  9752  10880  0.0758   (1563.0/20632.0)\n",
            "\n",
            "AUC: 0.9747044709329523\n",
            "Model saved to: /content/drive/My Drive/h2o_model_xgboost_only/XGBoost_1_AutoML_1_20250418_135015\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#default params xgboost"
      ],
      "metadata": {
        "id": "2ghWvuUiDPjq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train a default XGBoost model manually\n",
        "xgb_default = H2OXGBoostEstimator(seed=1)  # default params\n",
        "xgb_default.train(x=feature_columns, y=target_column, training_frame=train)\n",
        "\n",
        "# Predict\n",
        "preds = xgb_default.predict(test)\n",
        "\n",
        "# Evaluate\n",
        "print(\"\\nSample Predictions:\\n\", preds.head())\n",
        "\n",
        "perf = xgb_default.model_performance(test_data=test)\n",
        "print(\"\\nModel Performance on Test Set:\")\n",
        "print(perf)\n",
        "print(\"\\nConfusion Matrix:\\n\", perf.confusion_matrix())\n",
        "print(\"\\nAUC:\", perf.auc())\n",
        "\n",
        "# Variable importance (if supported)\n",
        "try:\n",
        "    print(\"\\nVariable Importance:\")\n",
        "    print(xgb_default.varimp(use_pandas=True))\n",
        "except:\n",
        "    print(\"Variable importance not available for this model.\")\n",
        "\n",
        "# Save the model\n",
        "model_path3 = h2o.save_model(model=xgb_default, path=\"/content/drive/My Drive/h2o_model_xgboost_only_Default\", force=True)\n",
        "print(\"Model saved to:\", model_path3)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybDgagdtDSBw",
        "outputId": "11a0c438-c1d8-4be8-f3b8-534fb0df429e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "xgboost Model Build progress: |██████████████████████████████████████████████████| (done) 100%\n",
            "xgboost prediction progress: |███████████████████████████████████████████████████| (done) 100%\n",
            "\n",
            "Sample Predictions:\n",
            "   predict           p0        p1\n",
            "        1  0.0051617    0.994838\n",
            "        1  0.0028429    0.997157\n",
            "        1  0.00489235   0.995108\n",
            "        1  0.00958383   0.990416\n",
            "        1  0.000906229  0.999094\n",
            "        1  0.049936     0.950064\n",
            "        1  0.169328     0.830672\n",
            "        1  0.00630349   0.993697\n",
            "        1  0.00327194   0.996728\n",
            "        1  0.375617     0.624383\n",
            "[10 rows x 3 columns]\n",
            "\n",
            "\n",
            "Model Performance on Test Set:\n",
            "ModelMetricsBinomial: xgboost\n",
            "** Reported on test data. **\n",
            "\n",
            "MSE: 0.06243290304707352\n",
            "RMSE: 0.2498657700587928\n",
            "LogLoss: 0.21391178506780664\n",
            "Mean Per-Class Error: 0.08208029741851922\n",
            "AUC: 0.9719187799142706\n",
            "AUCPR: 0.9677642547563013\n",
            "Gini: 0.9438375598285411\n",
            "\n",
            "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4705261041720708\n",
            "       0     1      Error    Rate\n",
            "-----  ----  -----  -------  ----------------\n",
            "0      9234  1071   0.1039   (1071.0/10305.0)\n",
            "1      622   9705   0.0602   (622.0/10327.0)\n",
            "Total  9856  10776  0.0821   (1693.0/20632.0)\n",
            "\n",
            "Maximum Metrics: Maximum metrics at their respective thresholds\n",
            "metric                       threshold    value     idx\n",
            "---------------------------  -----------  --------  -----\n",
            "max f1                       0.470526     0.919774  210\n",
            "max f2                       0.24076      0.946819  281\n",
            "max f0point5                 0.678677     0.925454  150\n",
            "max accuracy                 0.498508     0.918088  202\n",
            "max precision                0.998514     1         0\n",
            "max recall                   0.0117828    1         386\n",
            "max specificity              0.998514     1         0\n",
            "max absolute_mcc             0.470526     0.836671  210\n",
            "max min_per_class_accuracy   0.5493       0.916448  188\n",
            "max mean_per_class_accuracy  0.498508     0.918073  202\n",
            "max tns                      0.998514     10305     0\n",
            "max fns                      0.998514     10148     0\n",
            "max fps                      0.00099661   10305     399\n",
            "max tps                      0.0117828    10327     386\n",
            "max tnr                      0.998514     1         0\n",
            "max fnr                      0.998514     0.982667  0\n",
            "max fpr                      0.00099661   1         399\n",
            "max tpr                      0.0117828    1         386\n",
            "\n",
            "Gains/Lift Table: Avg response rate: 50.05 %, avg score: 50.30 %\n",
            "group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
            "-------  --------------------------  -----------------  ----------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
            "1        0.010033                    0.997826           1.99787     1.99787            1                0.998452    1                           0.998452            0.0200445       0.0200445                  99.787    99.787             0.0200445\n",
            "2        0.0203567                   0.997237           1.99787     1.99787            1                0.997469    1                           0.997954            0.0206255       0.0406701                  99.787    99.787             0.0406701\n",
            "3        0.0302443                   0.99631            1.99787     1.99787            1                0.99671     1                           0.997547            0.019754        0.0604241                  99.787    99.787             0.0604241\n",
            "4        0.0420706                   0.995564           1.99787     1.99787            1                0.995842    1                           0.997068            0.0236274       0.0840515                  99.787    99.787             0.0840515\n",
            "5        0.051425                    0.995245           1.99787     1.99787            1                0.995301    1                           0.996746            0.0186889       0.10274                    99.787    99.787             0.10274\n",
            "6        0.100087                    0.981771           1.96802     1.98336            0.98506          0.988932    0.992736                    0.992947            0.0957684       0.198509                   96.8021   98.3357            0.197053\n",
            "7        0.15001                     0.968832           1.9455      1.97076            0.973786         0.975163    0.98643                     0.987029            0.097124        0.295633                   94.5498   97.0758            0.291557\n",
            "8        0.200029                    0.957743           1.93979     1.96301            0.97093          0.963032    0.982554                    0.981028            0.0970272       0.39266                    93.9792   96.3015            0.385673\n",
            "9        0.300019                    0.931116           1.92233     1.94946            0.962191         0.946168    0.975767                    0.96941             0.192215        0.584875                   92.2332   94.9456            0.570319\n",
            "10       0.400349                    0.821821           1.83186     1.91999            0.916908         0.889462    0.961017                    0.949375            0.18379         0.768665                   83.1863   91.9987            0.737418\n",
            "11       0.5                         0.549409           1.47508     1.83132            0.738327         0.684956    0.916634                    0.896675            0.146993        0.915658                   47.5081   83.1316            0.832203\n",
            "12       0.59999                     0.220736           0.681774    1.63974            0.341251         0.376352    0.820745                    0.809962            0.0681708       0.983829                   -31.8226  63.9741            0.768496\n",
            "13       0.699981                    0.0576167          0.132675    1.42446            0.0664081        0.121512    0.71299                     0.711619            0.0132662       0.997095                   -86.7325  42.4461            0.594863\n",
            "14       0.800213                    0.0200217          0.0231861   1.24894            0.0116054        0.0338758   0.625136                    0.626726            0.00232401      0.999419                   -97.6814  24.8941            0.398837\n",
            "15       0.899961                    0.00596486         0.00582469  1.11116            0.00291545       0.0119818   0.556172                    0.558591            0.000581001     1                          -99.4175  11.1159            0.200291\n",
            "16       1                           0.00015664         0           1                  0                0.00332466  0.500533                    0.503043            0               1                          -100      0                  0\n",
            "\n",
            "Confusion Matrix:\n",
            " Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4705261041720708\n",
            "       0     1      Error    Rate\n",
            "-----  ----  -----  -------  ----------------\n",
            "0      9234  1071   0.1039   (1071.0/10305.0)\n",
            "1      622   9705   0.0602   (622.0/10327.0)\n",
            "Total  9856  10776  0.0821   (1693.0/20632.0)\n",
            "\n",
            "AUC: 0.9719187799142706\n",
            "\n",
            "Variable Importance:\n",
            "    variable  relative_importance  scaled_importance  percentage\n",
            "0      C7698         21889.314453           1.000000    0.135879\n",
            "1      C5335         18010.033203           0.822777    0.111798\n",
            "2      C8493         15216.418945           0.695153    0.094457\n",
            "3      C4838         13544.985352           0.618794    0.084081\n",
            "4      C3373         13479.279297           0.615793    0.083673\n",
            "..       ...                  ...                ...         ...\n",
            "281    C5044             0.541557           0.000025    0.000003\n",
            "282     C197             0.496094           0.000023    0.000003\n",
            "283    C4000             0.428955           0.000020    0.000003\n",
            "284    C4371             0.415253           0.000019    0.000003\n",
            "285     C109             0.329529           0.000015    0.000002\n",
            "\n",
            "[286 rows x 4 columns]\n",
            "Model saved to: /content/drive/My Drive/h2o_model_xgboost_only_Default/XGBoost_model_python_1744983244334_1602\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# comparing results using confusion matrix, AUC"
      ],
      "metadata": {
        "id": "fBSClPYAF8jI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Create a dictionary of models to compare\n",
        "models = {\n",
        "    \"AutoML (All Algorithms)\": aml.leader,\n",
        "    \"AutoML (XGBoost Only)\": aml_xgb.leader,\n",
        "    \"Manual XGBoost (Default)\": xgb_default\n",
        "}\n",
        "\n",
        "# Convert test labels to numpy array for sklearn metrics\n",
        "y_true = test[target_column].as_data_frame().values.flatten()\n",
        "\n",
        "print(\"=== MODEL COMPARISON ===\\n\")\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    print(f\"\\n--- {model_name} ---\")\n",
        "\n",
        "    # Predict on test set\n",
        "    preds = model.predict(test)\n",
        "    preds_df = preds.as_data_frame()\n",
        "\n",
        "    # Convert predictions to numpy\n",
        "    if 'predict' in preds_df.columns:\n",
        "        y_pred = preds_df['predict'].values\n",
        "    else:\n",
        "        y_pred = preds_df.iloc[:, 0].values  # fallback\n",
        "\n",
        "    # Print H2O confusion matrix and AUC\n",
        "    perf = model.model_performance(test_data=test)\n",
        "    print(\"H2O Confusion Matrix:\\n\", perf.confusion_matrix())\n",
        "    print(\"AUC:\", perf.auc())\n",
        "\n",
        "    # Print scikit-learn metrics (for more detail)\n",
        "    print(\"\\nSklearn Classification Report:\")\n",
        "    print(classification_report(y_true, y_pred, digits=4))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BWi0jtmGGDX",
        "outputId": "0d805503-6a83-432b-dc33-bc4c4fa5b0b5"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/h2o/frame.py:1983: H2ODependencyWarning: Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install polars and pyarrow and use it as pandas_df = h2o_df.as_data_frame(use_multi_thread=True)\n",
            "\n",
            "  warnings.warn(\"Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== MODEL COMPARISON ===\n",
            "\n",
            "\n",
            "--- AutoML (All Algorithms) ---\n",
            "xgboost prediction progress: |███████████████████████████████████████████████████| (done) 100%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/h2o/frame.py:1983: H2ODependencyWarning: Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install polars and pyarrow and use it as pandas_df = h2o_df.as_data_frame(use_multi_thread=True)\n",
            "\n",
            "  warnings.warn(\"Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "H2O Confusion Matrix:\n",
            " Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.414814523675225\n",
            "       0     1      Error    Rate\n",
            "-----  ----  -----  -------  ----------------\n",
            "0      9247  1058   0.1027   (1058.0/10305.0)\n",
            "1      505   9822   0.0489   (505.0/10327.0)\n",
            "Total  9752  10880  0.0758   (1563.0/20632.0)\n",
            "AUC: 0.9747044709329523\n",
            "\n",
            "Sklearn Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9427    0.9033    0.9226     10305\n",
            "           1     0.9074    0.9452    0.9259     10327\n",
            "\n",
            "    accuracy                         0.9243     20632\n",
            "   macro avg     0.9250    0.9243    0.9243     20632\n",
            "weighted avg     0.9250    0.9243    0.9243     20632\n",
            "\n",
            "\n",
            "--- AutoML (XGBoost Only) ---\n",
            "xgboost prediction progress: |███████████████████████████████████████████████████| (done) 100%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/h2o/frame.py:1983: H2ODependencyWarning: Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install polars and pyarrow and use it as pandas_df = h2o_df.as_data_frame(use_multi_thread=True)\n",
            "\n",
            "  warnings.warn(\"Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "H2O Confusion Matrix:\n",
            " Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4406862386635372\n",
            "       0     1      Error    Rate\n",
            "-----  ----  -----  -------  ----------------\n",
            "0      9304  1001   0.0971   (1001.0/10305.0)\n",
            "1      520   9807   0.0504   (520.0/10327.0)\n",
            "Total  9824  10808  0.0737   (1521.0/20632.0)\n",
            "AUC: 0.9756336453948133\n",
            "\n",
            "Sklearn Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9406    0.9097    0.9249     10305\n",
            "           1     0.9127    0.9427    0.9275     10327\n",
            "\n",
            "    accuracy                         0.9262     20632\n",
            "   macro avg     0.9267    0.9262    0.9262     20632\n",
            "weighted avg     0.9266    0.9262    0.9262     20632\n",
            "\n",
            "\n",
            "--- Manual XGBoost (Default) ---\n",
            "xgboost prediction progress: |███████████████████████████████████████████████████| (done) 100%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/h2o/frame.py:1983: H2ODependencyWarning: Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install polars and pyarrow and use it as pandas_df = h2o_df.as_data_frame(use_multi_thread=True)\n",
            "\n",
            "  warnings.warn(\"Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "H2O Confusion Matrix:\n",
            " Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4705261041720708\n",
            "       0     1      Error    Rate\n",
            "-----  ----  -----  -------  ----------------\n",
            "0      9234  1071   0.1039   (1071.0/10305.0)\n",
            "1      622   9705   0.0602   (622.0/10327.0)\n",
            "Total  9856  10776  0.0821   (1693.0/20632.0)\n",
            "AUC: 0.9719187799142706\n",
            "\n",
            "Sklearn Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9356    0.8969    0.9159     10305\n",
            "           1     0.9012    0.9384    0.9194     10327\n",
            "\n",
            "    accuracy                         0.9177     20632\n",
            "   macro avg     0.9184    0.9177    0.9177     20632\n",
            "weighted avg     0.9184    0.9177    0.9177     20632\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import h2o\n",
        "# from h2o.automl import H2OAutoML\n",
        "# import numpy as np\n",
        "\n",
        "# # Load pre-saved files # i do that up incase i need to use with diff models or i can just load it again for each model\n",
        "\n",
        "\n",
        "# # Initialize H2O\n",
        "# h2o.init()\n",
        "\n",
        "# # Convert the dense numpy array X to an H2OFrame #WILL TRY SPARSE tfidf_matrix #X for dense but crashes all ram\n",
        "# X_h2o = h2o.H2OFrame(tfidf_matrix)\n",
        "\n",
        "# # Convert the numpy array y to an H2OFrame\n",
        "# # y_h2o = h2o.H2OFrame(y, column_names=['rating']).asfactor() #categoical now badal regression\n",
        "# y_h2o = h2o.H2OFrame(y.reshape(-1, 1), column_names=['rating']).asfactor() # reshaped to 2d to avvoid errors although it works 1d and h2o works too\n",
        "\n",
        "# # print(y_h2o['rating'].type) # Verify the type conversion\n",
        "\n",
        "# # Combine features (X) and target (y) into a single H2OFrame\n",
        "# df_h2o = X_h2o.cbind(y_h2o)\n",
        "\n",
        "# # Specify the target column and features\n",
        "# target_column = 'rating'\n",
        "# feature_columns = df_h2o.columns\n",
        "# feature_columns.remove(target_column)\n",
        "\n",
        "# # Split the data into training and testing sets (use H2O's split_frame method)\n",
        "# train, test = df_h2o.split_frame(ratios=[.8], seed=1)\n",
        "\n",
        "# #if you run the same code with the same seed, you’ll get the same results every time.\n",
        "\n",
        "\n",
        "# # Run AutoML with the training data\n",
        "# aml = H2OAutoML(max_models=10, seed=1, nfolds=5,  max_runtime_secs= 10800)  # will try with sparse but without max_runtime_secs=3600 and seee\n",
        "# aml.train(x=feature_columns, y=target_column, training_frame=train)\n",
        "\n",
        "# # View the leaderboard (top-performing models)\n",
        "# lb = aml.leaderboard\n",
        "# print(lb)\n",
        "\n",
        "# # Predict on the test set\n",
        "# preds = aml.predict(test)\n",
        "\n",
        "# # Evaluate the predictions\n",
        "# print(\"\\nSample Predictions:\\n\", preds.head())\n",
        "\n",
        "# # Get list of models from leaderboard\n",
        "# model_ids = list(aml.leaderboard['model_id'].as_data_frame().values.flatten())\n",
        "\n",
        "# # Inspect top model (best one)\n",
        "# top_model = h2o.get_model(model_ids[0])\n",
        "# print(f\"\\nBest model ID: {model_ids[0]}\")\n",
        "# print(\"Algorithm used:\", top_model.algo)\n",
        "\n",
        "# # Summary\n",
        "# try:\n",
        "#     print(\"\\nModel Summary:\")\n",
        "#     print(top_model.summary())\n",
        "# except:\n",
        "#     print(\"No summary available for this model.\")\n",
        "\n",
        "# # Hyperparameters\n",
        "# print(\"\\nHyperparameters:\")\n",
        "# print(top_model.params)\n",
        "\n",
        "# # Variable importance (if supported)\n",
        "# try:\n",
        "#     print(\"\\nVariable Importance:\")\n",
        "#     print(top_model.varimp(use_pandas=True))\n",
        "# except:\n",
        "#     print(\"Variable importance not available for this model.\")\n",
        "\n",
        "# # Evaluate on test set\n",
        "# perf = top_model.model_performance(test_data=test)\n",
        "# print(\"\\nModel Performance on Test Set:\")\n",
        "# print(perf)\n",
        "# print(\"\\nConfusion Matrix:\\n\", perf.confusion_matrix())\n",
        "# print(\"\\nAUC:\", perf.auc())\n",
        "\n",
        "# model_path = h2o.save_model(model=top_model, path=\"/content/drive/My Drive/h2o_model\", force=True)\n",
        "# print(\"Model saved to:\", model_path)\n",
        "\n",
        "# # # Shutdown the H2O cluster\n",
        "# # h2o.cluster().shutdown()"
      ],
      "metadata": {
        "id": "OSWAelXdOlsH"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Auto sklearn run. should do autogluon but didnt talk about it in thesis"
      ],
      "metadata": {
        "id": "-Ooj5lN3nAyo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install auto-sklearn"
      ],
      "metadata": {
        "id": "RvTGCBWongkK"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "# import scipy.sparse # Assuming tfidf_matrix is a scipy sparse matrix\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n",
        "# import autosklearn.classification\n",
        "# import time # To track time\n",
        "\n",
        "# # --- Load your data (assuming it's already loaded) ---\n",
        "# # Example: If you needed to load the sparse matrix (adjust path as needed)\n",
        "# # from scipy.sparse import load_npz\n",
        "# # tfidf_matrix = load_npz('/content/drive/My Drive/tfidf_matrix.npz') # If saved as .npz\n",
        "# # y = np.load('/content/drive/My Drive/labels_binary.npy')\n",
        "\n",
        "# # --- Ensure correct data types ---\n",
        "# # auto-sklearn expects X to be float and y to be int for classification\n",
        "# tfidf_matrix = tfidf_matrix.astype(np.float64)\n",
        "# y = y.astype(np.int32) # Or np.int64\n",
        "\n",
        "# print(\"Data loaded.\")\n",
        "# print(\"X shape:\", tfidf_matrix.shape)\n",
        "# print(\"y shape:\", y.shape)\n",
        "# print(\"Unique labels:\", np.unique(y))\n",
        "\n",
        "# # --- Split Data ---\n",
        "# # Stratify ensures the proportion of labels is the same in train and test sets\n",
        "# X_train, X_test, y_train, y_test = train_test_split(\n",
        "#     tfidf_matrix, y, test_size=0.2, random_state=42, stratify=y\n",
        "# )\n",
        "# print(\"Data split complete.\")\n",
        "# print(\"X_train shape:\", X_train.shape)\n",
        "# print(\"X_test shape:\", X_test.shape)\n",
        "\n",
        "# # --- Configure auto-sklearn ---\n",
        "# # Time limits are crucial! Expressed in seconds.\n",
        "# # time_left_for_this_task: Total time budget for the entire optimization process.\n",
        "# # per_run_time_limit: Max time allocated for evaluating a single pipeline.\n",
        "# automl_classifier = autosklearn.classification.AutoSklearnClassifier(\n",
        "#     time_left_for_this_task=3600,  # e.g., 1 hour total time\n",
        "#     per_run_time_limit=300,       # e.g., 5 minutes per model evaluation\n",
        "#     memory_limit=4096,            # Optional: Memory limit in MB (adjust based on your machine)\n",
        "#     n_jobs=-1,                    # Use all available CPU cores\n",
        "#     # Consider specifying a metric, esp. if classes are imbalanced\n",
        "#     # Default is accuracy. Others: 'roc_auc', 'f1', 'precision', 'recall' etc.\n",
        "#     # metric=autosklearn.metrics.roc_auc, # Example: Optimize for AUC\n",
        "#     seed=423,                      # For reproducibility\n",
        "#     # Important for sparse data: include appropriate preprocessors/classifiers\n",
        "#     # auto-sklearn usually detects sparse data, but you can guide it if needed\n",
        "#     # include={'feature_preprocessor': [\"no_preprocessing\"], # Since TF-IDF is already processed\n",
        "#     #          'classifier': [\"sgd\", \"passive_aggressive\", ...]} # Suggest sparse-friendly models\n",
        "# )\n",
        "\n",
        "# print(\"Auto-sklearn classifier configured. Starting search...\")\n",
        "# start_time = time.time()\n",
        "\n",
        "# # --- Train the model ---\n",
        "# automl_classifier.fit(X_train, y_train, dataset_name='tfidf_thesis_data')\n",
        "\n",
        "# end_time = time.time()\n",
        "# print(f\"Auto-sklearn training finished in {(end_time - start_time):.2f} seconds.\")\n",
        "\n",
        "# # --- Evaluate the best model found ---\n",
        "# print(\"Evaluating on the test set...\")\n",
        "# y_pred = automl_classifier.predict(X_test)\n",
        "# y_proba = automl_classifier.predict_proba(X_test)[:, 1] # Probability for the positive class (class 1)\n",
        "\n",
        "# accuracy = accuracy_score(y_test, y_pred)\n",
        "# auc = roc_auc_score(y_test, y_proba) # Use probabilities for AUC\n",
        "\n",
        "# print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "# print(f\"Test AUC: {auc:.4f}\")\n",
        "# print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "# # --- Inspect the results ---\n",
        "# print(\"\\n--- Auto-sklearn Leaderboard ---\")\n",
        "# print(automl_classifier.leaderboard())\n",
        "\n",
        "# print(\"\\n--- Best Model Found ---\")\n",
        "# # Shows the ensemble composition or the single best model\n",
        "# print(automl_classifier.show_models())\n",
        "\n",
        "# # You can also get statistics about the run\n",
        "# # print(automl_classifier.sprint_statistics())"
      ],
      "metadata": {
        "id": "Rjzi5QuxCn70"
      },
      "execution_count": 27,
      "outputs": []
    }
  ]
}