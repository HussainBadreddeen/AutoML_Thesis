{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMOtIrCbTir+ql+1uYmK2Al",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HussainBadreddeen/AutoML_Thesis/blob/main/new_env_for_TPOT_and_H2o.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "voRCIQMwON5f",
        "outputId": "aafb3904-03ff-4bdf-8021-bf17c160122f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# df_normalized_reviews.to_csv(\"/content/drive/My Drive/processed_data.csv\", index=False, encoding=\"utf-8-sig\") #fixed it utf-8 doesnt wokr although it did before\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "#load it back\n",
        "df_normalized_reviews2 = pd.read_csv(\"/content/drive/My Drive/processed_data.csv\") #the nan row comes back somehow\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(df_normalized_reviews2[df_normalized_reviews2.isna().any(axis=1)])\n",
        "empty_or_nan_values = df_normalized_reviews2[df_normalized_reviews2.isna().any(axis=1)]\n",
        "empty_or_nan_values\n",
        "\n",
        "df_normalized_reviews2 = df_normalized_reviews2[df_normalized_reviews2['stemmed_text'].notna()]  # remove rows where stemmed_text is NaN\n",
        "print(df_normalized_reviews2[df_normalized_reviews2.isna().any(axis=1)])\n",
        "empty_or_nan_values = df_normalized_reviews2[df_normalized_reviews2.isna().any(axis=1)]\n",
        "empty_or_nan_values\n",
        "#i saved the dataset again after here and now it doesnt need removing this line again so no need to run this cell anymore"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "K-aFPVimOXEk",
        "outputId": "37d078e8-769e-46c1-a613-489aaf7968fd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty DataFrame\n",
            "Columns: [rating, review, normalized_review, tokens, filtered_tokens, stemmed_text]\n",
            "Index: []\n",
            "Empty DataFrame\n",
            "Columns: [rating, review, normalized_review, tokens, filtered_tokens, stemmed_text]\n",
            "Index: []\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [rating, review, normalized_review, tokens, filtered_tokens, stemmed_text]\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ce872116-57e9-4f83-bbdf-2216d2a387bf\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rating</th>\n",
              "      <th>review</th>\n",
              "      <th>normalized_review</th>\n",
              "      <th>tokens</th>\n",
              "      <th>filtered_tokens</th>\n",
              "      <th>stemmed_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ce872116-57e9-4f83-bbdf-2216d2a387bf')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ce872116-57e9-4f83-bbdf-2216d2a387bf button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ce872116-57e9-4f83-bbdf-2216d2a387bf');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_eb0a260e-2318-4435-a1a2-daac9334c0a1\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('empty_or_nan_values')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_eb0a260e-2318-4435-a1a2-daac9334c0a1 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('empty_or_nan_values');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "empty_or_nan_values",
              "repr_error": "Out of range float values are not JSON compliant: nan"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer # this is good: https://www.youtube.com/watch?v=rcovF6S1oFI\n",
        "tfidf_vectorizer = TfidfVectorizer(\n",
        "     # max_features=10000,      # Limit to 10k features # update i will use just min and max and wont test chunking on all 71k unique words/features\n",
        "    min_df=5,                # Remove rare words (appearing in less than 5 documents/rows)\n",
        "    max_df=0.8,              # Remove overly common words (appearing in more than 80% of documents)\n",
        "    dtype=np.float32          # Use float32 to save memory\n",
        ")\n",
        "\n",
        "\n",
        "# Fit and transform the stemmed text vocab\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(df_normalized_reviews2[\"stemmed_text\"])\n",
        "\n",
        "# Print the shape of the matrix\n",
        "print(\"Shape of the TF-IDF matrix:\", tfidf_matrix.shape)\n",
        "#converting the sparse matrix to dense in case i need to use the dense matrix\n",
        "# X_dense = tfidf_matrix.astype(np.float32).toarray()\n",
        "\n",
        "# np.save('C:/Users/hussa/OneDrive/Desktop/thesis_code/tfidf_dense.npy', X_dense)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ka4bRtawO2cz",
        "outputId": "dd348df6-ed68-4c9f-dbda-d11863a1a8fa"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of the TF-IDF matrix: (102961, 9819)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#update using 71k words seems unprofessional might overfit and introduce noise and computation problems as im having them already.\n",
        "\n",
        "#will probably use min_df and max_df to limit words more and try dense matrix again on drive first then maybe local but will always opt for drive till exhaustion"
      ],
      "metadata": {
        "id": "gtCvb1V-fw5O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#loading dense matrix and ratings from drive"
      ],
      "metadata": {
        "id": "jYv04wXUZMA0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Load pre-saved files #the labels are already mapped and the dense matrix is already ready and is 3.7gb (9.8k words converted using float32 isntead of 64) insteado of 55gb with all words\n",
        "X = np.load('C:/Users/hussa/OneDrive/Desktop/thesis_code/tfidf_dense.npy', mmap_mode='r')  # efficient read\n",
        "y = np.load('C:/Users/hussa/OneDrive/Desktop/thesis_code/labels_binary.npy')"
      ],
      "metadata": {
        "id": "R6e8EMrGZLLL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# H2o attempt in running with dense matrix and mapped ratings"
      ],
      "metadata": {
        "id": "J-gyA3G_ZsKt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install h2o"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mzQoVcQ8gkp3",
        "outputId": "9bdeff14-00d9-4e90-ed5d-390b77f0596d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting h2o\n",
            "  Using cached h2o-3.46.0.7-py2.py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from h2o) (2.32.3)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (from h2o) (0.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->h2o) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->h2o) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->h2o) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->h2o) (2025.1.31)\n",
            "Downloading h2o-3.46.0.7-py2.py3-none-any.whl (265.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m265.9/265.9 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: h2o\n",
            "Successfully installed h2o-3.46.0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import h2o\n",
        "from h2o.automl import H2OAutoML\n",
        "import numpy as np\n",
        "\n",
        "# Load pre-saved files # i do that up incase i need to use with diff models or i can just load it again for each model\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "X = np.load('/content/drive/My Drive/tfidf_dense.npy', mmap_mode='r')  # efficient read\n",
        "y = np.load('/content/drive/My Drive/labels_binary.npy')\n",
        "\n",
        "# Initialize H2O\n",
        "h2o.init()\n",
        "\n",
        "# Convert the dense numpy array X to an H2OFrame #WILL TRY SPARSE tfidf_matrix #X for dense but crashes all ram\n",
        "X_h2o = h2o.H2OFrame(tfidf_matrix)\n",
        "\n",
        "# Convert the numpy array y to an H2OFrame\n",
        "# y_h2o = h2o.H2OFrame(y, column_names=['rating']).asfactor() #categoical now badal regression\n",
        "y_h2o = h2o.H2OFrame(y.reshape(-1, 1), column_names=['rating']).asfactor() # reshaped to 2d to avvoid errors although it works 1d and h2o works too\n",
        "\n",
        "# print(y_h2o['rating'].type) # Verify the type conversion\n",
        "\n",
        "# Combine features (X) and target (y) into a single H2OFrame\n",
        "df_h2o = X_h2o.cbind(y_h2o)\n",
        "\n",
        "# Specify the target column and features\n",
        "target_column = 'rating'\n",
        "feature_columns = df_h2o.columns\n",
        "feature_columns.remove(target_column)\n",
        "\n",
        "# Split the data into training and testing sets (use H2O's split_frame method)\n",
        "train, test = df_h2o.split_frame(ratios=[.8], seed=1) #seed =1 to ensure that the random operations (like the train-test split or cross-validation splits) produce the same results each time the code is run so we can reproduce same results\n",
        "\n",
        "#if you run the same code with the same seed, you’ll get the same results every time.\n",
        "\n",
        "\n",
        "# Run AutoML with the training data\n",
        "aml = H2OAutoML(max_models=10, seed=1, nfolds=5)  # will try with sparse but without max_runtime_secs=3600 and seee\n",
        "aml.train(x=feature_columns, y=target_column, training_frame=train)\n",
        "\n",
        "# View the leaderboard (top-performing models)\n",
        "lb = aml.leaderboard\n",
        "print(lb)\n",
        "\n",
        "# Predict on the test set\n",
        "preds = aml.predict(test)\n",
        "\n",
        "# Evaluate the predictions\n",
        "print(\"\\nSample Predictions:\\n\", preds.head())\n",
        "\n",
        "# Get list of models from leaderboard\n",
        "model_ids = list(aml.leaderboard['model_id'].as_data_frame().values.flatten())\n",
        "\n",
        "# Inspect top model (best one)\n",
        "top_model = h2o.get_model(model_ids[0])\n",
        "print(f\"\\nBest model ID: {model_ids[0]}\")\n",
        "print(\"Algorithm used:\", top_model.algo)\n",
        "\n",
        "# Summary\n",
        "try:\n",
        "    print(\"\\nModel Summary:\")\n",
        "    print(top_model.summary())\n",
        "except:\n",
        "    print(\"No summary available for this model.\")\n",
        "\n",
        "# Hyperparameters\n",
        "print(\"\\nHyperparameters:\")\n",
        "print(top_model.params)\n",
        "\n",
        "# Variable importance (if supported)\n",
        "try:\n",
        "    print(\"\\nVariable Importance:\")\n",
        "    print(top_model.varimp(use_pandas=True))\n",
        "except:\n",
        "    print(\"Variable importance not available for this model.\")\n",
        "\n",
        "# Evaluate on test set\n",
        "perf = top_model.model_performance(test_data=test)\n",
        "print(\"\\nModel Performance on Test Set:\")\n",
        "print(perf)\n",
        "print(\"\\nConfusion Matrix:\\n\", perf.confusion_matrix())\n",
        "print(\"\\nAUC:\", perf.auc())\n",
        "\n",
        "model_path = h2o.save_model(model=top_model, path=\"/content/drive/My Drive/h2o_model\", force=True)\n",
        "print(\"Model saved to:\", model_path)\n",
        "\n",
        "# Shutdown the H2O cluster\n",
        "h2o.cluster().shutdown()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "id": "OSWAelXdOlsH",
        "outputId": "3cfe573d-3153-47fc-87ad-cc6452e9840b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Checking whether there is an H2O instance running at http://localhost:54321. connected.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "--------------------------  -----------------------------------------------------------------------------------------\n",
              "H2O_cluster_uptime:         45 mins 53 secs\n",
              "H2O_cluster_timezone:       Etc/UTC\n",
              "H2O_data_parsing_timezone:  UTC\n",
              "H2O_cluster_version:        3.46.0.7\n",
              "H2O_cluster_version_age:    15 days\n",
              "H2O_cluster_name:           H2O_from_python_unknownUser_lhh5fc\n",
              "H2O_cluster_total_nodes:    1\n",
              "H2O_cluster_free_memory:    2.957 Gb\n",
              "H2O_cluster_total_cores:    2\n",
              "H2O_cluster_allowed_cores:  2\n",
              "H2O_cluster_status:         locked, healthy\n",
              "H2O_connection_url:         http://localhost:54321\n",
              "H2O_connection_proxy:       {\"http\": null, \"https\": null, \"colab_language_server\": \"/usr/colab/bin/language_service\"}\n",
              "H2O_internal_security:      False\n",
              "Python_version:             3.11.12 final\n",
              "--------------------------  -----------------------------------------------------------------------------------------"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "\n",
              "#h2o-table-4.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-4 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-4 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-4 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-4 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-4 .h2o-table th,\n",
              "#h2o-table-4 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-4 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-4\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption></caption>\n",
              "    <thead></thead>\n",
              "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
              "<td>45 mins 53 secs</td></tr>\n",
              "<tr><td>H2O_cluster_timezone:</td>\n",
              "<td>Etc/UTC</td></tr>\n",
              "<tr><td>H2O_data_parsing_timezone:</td>\n",
              "<td>UTC</td></tr>\n",
              "<tr><td>H2O_cluster_version:</td>\n",
              "<td>3.46.0.7</td></tr>\n",
              "<tr><td>H2O_cluster_version_age:</td>\n",
              "<td>15 days</td></tr>\n",
              "<tr><td>H2O_cluster_name:</td>\n",
              "<td>H2O_from_python_unknownUser_lhh5fc</td></tr>\n",
              "<tr><td>H2O_cluster_total_nodes:</td>\n",
              "<td>1</td></tr>\n",
              "<tr><td>H2O_cluster_free_memory:</td>\n",
              "<td>2.957 Gb</td></tr>\n",
              "<tr><td>H2O_cluster_total_cores:</td>\n",
              "<td>2</td></tr>\n",
              "<tr><td>H2O_cluster_allowed_cores:</td>\n",
              "<td>2</td></tr>\n",
              "<tr><td>H2O_cluster_status:</td>\n",
              "<td>locked, healthy</td></tr>\n",
              "<tr><td>H2O_connection_url:</td>\n",
              "<td>http://localhost:54321</td></tr>\n",
              "<tr><td>H2O_connection_proxy:</td>\n",
              "<td>{\"http\": null, \"https\": null, \"colab_language_server\": \"/usr/colab/bin/language_service\"}</td></tr>\n",
              "<tr><td>H2O_internal_security:</td>\n",
              "<td>False</td></tr>\n",
              "<tr><td>Python_version:</td>\n",
              "<td>3.11.12 final</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
            "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
            "AutoML progress: |███████████████████████████████████████████████████████████████"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Auto sklearn run. should do autogluon but didnt talk about it in thesis"
      ],
      "metadata": {
        "id": "-Ooj5lN3nAyo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install auto-sklearn"
      ],
      "metadata": {
        "id": "RvTGCBWongkK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy.sparse # Assuming tfidf_matrix is a scipy sparse matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n",
        "import autosklearn.classification\n",
        "import time # To track time\n",
        "\n",
        "# --- Load your data (assuming it's already loaded) ---\n",
        "# Example: If you needed to load the sparse matrix (adjust path as needed)\n",
        "# from scipy.sparse import load_npz\n",
        "# tfidf_matrix = load_npz('/content/drive/My Drive/tfidf_matrix.npz') # If saved as .npz\n",
        "# y = np.load('/content/drive/My Drive/labels_binary.npy')\n",
        "\n",
        "# --- Ensure correct data types ---\n",
        "# auto-sklearn expects X to be float and y to be int for classification\n",
        "tfidf_matrix = tfidf_matrix.astype(np.float64)\n",
        "y = y.astype(np.int32) # Or np.int64\n",
        "\n",
        "print(\"Data loaded.\")\n",
        "print(\"X shape:\", tfidf_matrix.shape)\n",
        "print(\"y shape:\", y.shape)\n",
        "print(\"Unique labels:\", np.unique(y))\n",
        "\n",
        "# --- Split Data ---\n",
        "# Stratify ensures the proportion of labels is the same in train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    tfidf_matrix, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "print(\"Data split complete.\")\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "\n",
        "# --- Configure auto-sklearn ---\n",
        "# Time limits are crucial! Expressed in seconds.\n",
        "# time_left_for_this_task: Total time budget for the entire optimization process.\n",
        "# per_run_time_limit: Max time allocated for evaluating a single pipeline.\n",
        "automl_classifier = autosklearn.classification.AutoSklearnClassifier(\n",
        "    time_left_for_this_task=3600,  # e.g., 1 hour total time\n",
        "    per_run_time_limit=300,       # e.g., 5 minutes per model evaluation\n",
        "    memory_limit=4096,            # Optional: Memory limit in MB (adjust based on your machine)\n",
        "    n_jobs=-1,                    # Use all available CPU cores\n",
        "    # Consider specifying a metric, esp. if classes are imbalanced\n",
        "    # Default is accuracy. Others: 'roc_auc', 'f1', 'precision', 'recall' etc.\n",
        "    # metric=autosklearn.metrics.roc_auc, # Example: Optimize for AUC\n",
        "    seed=423,                      # For reproducibility\n",
        "    # Important for sparse data: include appropriate preprocessors/classifiers\n",
        "    # auto-sklearn usually detects sparse data, but you can guide it if needed\n",
        "    # include={'feature_preprocessor': [\"no_preprocessing\"], # Since TF-IDF is already processed\n",
        "    #          'classifier': [\"sgd\", \"passive_aggressive\", ...]} # Suggest sparse-friendly models\n",
        ")\n",
        "\n",
        "print(\"Auto-sklearn classifier configured. Starting search...\")\n",
        "start_time = time.time()\n",
        "\n",
        "# --- Train the model ---\n",
        "automl_classifier.fit(X_train, y_train, dataset_name='tfidf_thesis_data')\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Auto-sklearn training finished in {(end_time - start_time):.2f} seconds.\")\n",
        "\n",
        "# --- Evaluate the best model found ---\n",
        "print(\"Evaluating on the test set...\")\n",
        "y_pred = automl_classifier.predict(X_test)\n",
        "y_proba = automl_classifier.predict_proba(X_test)[:, 1] # Probability for the positive class (class 1)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "auc = roc_auc_score(y_test, y_proba) # Use probabilities for AUC\n",
        "\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Test AUC: {auc:.4f}\")\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "# --- Inspect the results ---\n",
        "print(\"\\n--- Auto-sklearn Leaderboard ---\")\n",
        "print(automl_classifier.leaderboard())\n",
        "\n",
        "print(\"\\n--- Best Model Found ---\")\n",
        "# Shows the ensemble composition or the single best model\n",
        "print(automl_classifier.show_models())\n",
        "\n",
        "# You can also get statistics about the run\n",
        "# print(automl_classifier.sprint_statistics())"
      ],
      "metadata": {
        "id": "Rjzi5QuxCn70"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}